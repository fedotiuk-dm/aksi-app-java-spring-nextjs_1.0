# Docker Compose v3.8 with production best practices
version: "3.8"

# External environment files for sensitive data
x-environment: &default-environment
  env_file:
    - .env.vps
  environment:
    - TZ=UTC
    - LANG=en_US.UTF-8
    - LC_ALL=en_US.UTF-8

# Common labels for all services
x-common-labels: &common-labels
  labels:
    - "project=aksi-app"
    - "environment=vps"
    - "managed-by=docker-compose"

# Logging configuration for all services
x-logging: &default-logging
  logging:
    driver: "json-file"
    options:
      max-size: "100m"
      max-file: "5"
      labels: "production_status"

# Security configuration
x-security: &default-security
  security_opt:
    - no-new-privileges:true
  read_only: true
  tmpfs:
    - /tmp:noexec,nosuid,size=100m

services:
  # PostgreSQL - Main database for the application
  postgres:
    <<: [*default-environment, *common-labels, *default-logging]
    image: postgres:17-alpine
    container_name: postgres-vps
    hostname: postgres-vps
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: ${DB_USER:-aksi_user}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-1911}
      POSTGRES_DB: ${DB_NAME:-aksi_cleaners_db_v5}
      POSTGRES_SCHEMA: public
      # Performance optimizations for VPS
      POSTGRES_SHARED_BUFFERS: 256MB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 1GB
      POSTGRES_WORK_MEM: 4MB
      POSTGRES_MAINTENANCE_WORK_MEM: 64MB
      POSTGRES_CHECKPOINT_COMPLETION_TARGET: 0.9
      POSTGRES_WAL_BUFFERS: 16MB
      POSTGRES_DEFAULT_STATISTICS_TARGET: 100
      # Security
      POSTGRES_INITDB_ARGS: "--auth-host=scram-sha-256 --auth-local=scram-sha-256"
    volumes:
      - postgres_data_vps:/var/lib/postgresql/data
      - ./postgres/init.sql:/docker-entrypoint-initdb.d/01-init.sql:ro
      - ./postgres/conf.d:/etc/postgresql/conf.d:ro
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "pg_isready -U ${DB_USER:-aksi_user} -d ${DB_NAME:-aksi_cleaners_db_v5}",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - aksi-network-vps
    # Optimized resource limits for 8GB VPS
    deploy:
      resources:
        limits:
          memory: 1.5G
          cpus: "1.0"
        reservations:
          memory: 512M
          cpus: "0.5"
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    # Additional production settings
    ulimits:
      nofile:
        soft: 1024
        hard: 2048
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETGID
      - SETUID

  # PostgreSQL - Separate database for GlitchTip
  postgres-glitchtip:
    <<: [*default-environment, *common-labels, *default-logging]
    image: postgres:17-alpine
    container_name: postgres-glitchtip-vps
    hostname: postgres-glitchtip-vps
    expose:
      - "5432"
    environment:
      POSTGRES_USER: ${GLITCHTIP_DB_USER:-glitchtip}
      POSTGRES_PASSWORD: ${GLITCHTIP_DB_PASSWORD:-glitchtip_pass}
      POSTGRES_DB: ${GLITCHTIP_DB_NAME:-glitchtip}
      POSTGRES_SCHEMA: public
      # Optimized for GlitchTip workload
      POSTGRES_SHARED_BUFFERS: 128MB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 256MB
      POSTGRES_WORK_MEM: 2MB
      POSTGRES_MAINTENANCE_WORK_MEM: 32MB
      # Security
      POSTGRES_INITDB_ARGS: "--auth-host=scram-sha-256 --auth-local=scram-sha-256"
    volumes:
      - postgres_glitchtip_data_vps:/var/lib/postgresql/data
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "pg_isready -U ${GLITCHTIP_DB_USER:-glitchtip} -d ${GLITCHTIP_DB_NAME:-glitchtip}",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    networks:
      - aksi-network-vps
    # Resource limits for GlitchTip DB
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
        reservations:
          memory: 256M
          cpus: "0.25"
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    ulimits:
      nofile:
        soft: 512
        hard: 1024
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETGID
      - SETUID

  # Redis - High-performance session store and cache
  redis:
    <<: [*default-environment, *common-labels, *default-logging]
    image: redis:8-alpine
    container_name: redis-vps
    hostname: redis-vps
    ports:
      - "6379:6379"
    command: >
      redis-server
      --maxmemory 128mb
      --maxmemory-policy allkeys-lru
      --tcp-keepalive 300
      --timeout 300
      --tcp-backlog 128
      --databases 16
      --save 900 1
      --save 300 10
      --save 60 10000
      --appendonly yes
      --appendfsync everysec
      --auto-aof-rewrite-percentage 100
      --auto-aof-rewrite-min-size 64mb
      --no-appendfsync-on-rewrite no
      --loglevel notice
    volumes:
      - redis_data_vps:/data
      - redis_conf_vps:/etc/redis
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - aksi-network-vps
    # Optimized resource limits for 8GB VPS
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: "0.25"
        reservations:
          memory: 128M
          cpus: "0.1"
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    ulimits:
      nofile:
        soft: 1024
        hard: 2048
    cap_drop:
      - ALL
    cap_add:
      - SETGID
      - SETUID
    # Security hardening
    security_opt:
      - no-new-privileges:true
    read_only: false

  # PgAdmin - Database management interface
  pgadmin:
    <<: [*default-environment, *common-labels, *default-logging]
    image: dpage/pgadmin4:9.5
    container_name: aksi-pgadmin-vps
    hostname: pgadmin-vps
    ports:
      - "5050:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_EMAIL:-admin@aksi.com}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD:-admin}
      PGADMIN_CONFIG_SERVER_MODE: "False"
      PGADMIN_CONFIG_MASTER_PASSWORD_REQUIRED: "False"
      PGADMIN_CONFIG_ALLOW_SAVE_PASSWORD: "True"
      PGADMIN_CONFIG_ALLOW_SAVE_TUNNEL_PASSWORD: "False"
      # Security settings
      PGADMIN_CONFIG_LOGIN_BANNER: "AKSI Database Management"
      PGADMIN_CONFIG_PASSWORD_LENGTH_MIN: "8"
      # Performance settings
      PGADMIN_CONFIG_DATA_CONNECT_TIMEOUT: "10"
    volumes:
      - pgadmin_data_vps:/var/lib/pgadmin
      - pgadmin_config_vps:/pgadmin4/config_local.py
      - ./pgadmin/servers.json:/pgadmin4/servers.json:ro
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      postgres-glitchtip:
        condition: service_healthy
    healthcheck:
      test:
        [
          "CMD-SHELL",
          'python3 -c "import requests; requests.get(''http://localhost:80/login'', timeout=5)"',
        ]
      interval: 60s
      timeout: 15s
      retries: 3
      start_period: 30s
    networks:
      - aksi-network-vps
    # Optimized resource limits for 8GB VPS
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
        reservations:
          memory: 256M
          cpus: "0.25"
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
        window: 120s
    ulimits:
      nofile:
        soft: 512
        hard: 1024
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
    security_opt:
      - no-new-privileges:true

  # Backend - Spring Boot Application Server
  backend:
    <<: [*default-environment, *common-labels, *default-logging]
    build:
      context: ../backend
      dockerfile: Dockerfile.dev
      args:
        BUILD_ENV: vps
    container_name: backend-vps
    hostname: backend-vps
    ports:
      - "8080:8080"
      - "5005:5005" # Debug port (remove in production)
    environment:
      SPRING_DATASOURCE_URL: jdbc:postgresql://${DB_HOST:-postgres}:${DB_PORT:-5432}/${DB_NAME:-aksi_cleaners_db_v5}
      SPRING_DATASOURCE_USERNAME: ${DB_USER:-aksi_user}
      SPRING_DATASOURCE_PASSWORD: ${DB_PASSWORD:-1911}
      SPRING_PROFILES_ACTIVE: vps
      # JVM optimization for 8GB VPS
      JAVA_OPTS: >
        -Xms512m
        -Xmx2g
        -XX:+UseG1GC
        -XX:MaxGCPauseMillis=200
        -XX:+UseStringDeduplication
        -XX:+OptimizeStringConcat
        -XX:+DisableExplicitGC
        -XX:+UseCompressedOops
        -Djava.security.egd=file:/dev/./urandom
      # Spring optimization
      SPRING_DEVTOOLS_RESTART_ENABLED: "false"
      SPRING_DEVTOOLS_LIVERELOAD_ENABLED: "false"
      # Optimized logging for production
      AKSI_LOG_LEVEL: "INFO"
      LOGGING_LEVEL_COM_AKSI: "INFO"
      LOGGING_LEVEL_ROOT: "WARN"
      LOGGING_PATTERN_CONSOLE: "%d{yyyy-MM-dd HH:mm:ss} - %msg%n"
      # Database connection pool
      SPRING_DATASOURCE_HIKARI_MAXIMUM_POOL_SIZE: "20"
      SPRING_DATASOURCE_HIKARI_MINIMUM_IDLE: "5"
      SPRING_DATASOURCE_HIKARI_CONNECTION_TIMEOUT: "20000"
      SPRING_DATASOURCE_HIKARI_IDLE_TIMEOUT: "300000"
      SPRING_DATASOURCE_HIKARI_MAX_LIFETIME: "1200000"
      # File storage configuration
      FILE_UPLOAD_DIR: /app/uploads
      FILE_BASE_URL: http://localhost:8080
      # Redis configuration
      SPRING_DATA_REDIS_HOST: redis
      SPRING_DATA_REDIS_PORT: 6379
      SPRING_DATA_REDIS_TIMEOUT: 2000ms
      # GlitchTip configuration
      GLITCHTIP_DSN: ${GLITCHTIP_DSN:-http://b1abf81086f84a71bc66b1659e647402@glitchtip:8000/1}
      GLITCHTIP_DEBUG: "false"
      GLITCHTIP_TRACES_SAMPLE_RATE: "0.1"
      # Security headers
      SERVER_COMPRESSION_ENABLED: "true"
      SERVER_COMPRESSION_MIN_RESPONSE_SIZE: "1024"
      SERVER_COMPRESSION_MIME_TYPES: "text/html,text/xml,text/plain,text/css,text/javascript,application/javascript,application/json"
    volumes:
      - ../backend/src:/app/src:ro
      - ../backend/target:/app/target:ro
      - backend_m2_cache:/home/appuser/.m2
      - backend_uploads:/app/uploads
      - ./backend/application-vps.yml:/app/src/main/resources/application-vps.yml:ro
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    restart: unless-stopped
    networks:
      - aksi-network-vps
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget -q --spider http://localhost:8080/management/health || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    # Optimized resource limits for 8GB VPS
    deploy:
      resources:
        limits:
          memory: 2.5G
          cpus: "1.5"
        reservations:
          memory: 1G
          cpus: "0.75"
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 3
        window: 120s
    ulimits:
      nofile:
        soft: 1024
        hard: 2048
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
    security_opt:
      - no-new-privileges:true

  # GlitchTip - Error Monitoring (VPS)
  glitchtip:
    build:
      context: .
      dockerfile: Dockerfile.glitchtip
    container_name: glitchtip-vps
    ports:
      - "8000:8000"
    environment:
      # Database settings (як в офіційному прикладі)
      DATABASE_URL: postgres://glitchtip:glitchtip_pass@postgres-glitchtip:5432/glitchtip
      SECRET_KEY: "change_me_to_something_random_please_generate_new_key"
      PORT: 8000
      EMAIL_URL: consolemail://
      GLITCHTIP_DOMAIN: http://localhost:8000
      DEFAULT_FROM_EMAIL: admin@glitchtip.local
      CELERY_WORKER_AUTOSCALE: "1,3"
      REDIS_URL: redis://redis:6379/1
      DEBUG: "false"
      ALLOWED_HOSTS: "localhost,127.0.0.1,glitchtip"
    volumes:
      - glitchtip_uploads_vps:/code/uploads
    depends_on:
      postgres-glitchtip:
        condition: service_healthy
      redis:
        condition: service_started
    restart: unless-stopped
    networks:
      - aksi-network-vps
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    # Optimized resource limits for 8GB VPS
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "0.75"
        reservations:
          memory: 512M
          cpus: "0.5"

  # GlitchTip Worker (for Celery tasks)
  glitchtip-worker:
    build:
      context: .
      dockerfile: Dockerfile.glitchtip
    container_name: glitchtip-worker-vps
    command: ./bin/run-celery-with-beat.sh
    environment:
      DATABASE_URL: postgres://glitchtip:glitchtip_pass@postgres-glitchtip:5432/glitchtip
      SECRET_KEY: "change_me_to_something_random_please_generate_new_key"
      PORT: 8000
      EMAIL_URL: consolemail://
      GLITCHTIP_DOMAIN: http://localhost:8000
      DEFAULT_FROM_EMAIL: admin@glitchtip.local
      CELERY_WORKER_AUTOSCALE: "1,3"
      REDIS_URL: redis://redis:6379/1
      DEBUG: "false"
      ALLOWED_HOSTS: "localhost,127.0.0.1,glitchtip"
    volumes:
      - glitchtip_uploads_vps:/code/uploads
    depends_on:
      - postgres-glitchtip
      - redis
    restart: unless-stopped
    networks:
      - aksi-network-vps
    # Resource limits for GlitchTip Worker
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
        reservations:
          memory: 256M
          cpus: "0.25"

  # GlitchTip Migrate (for database migrations)
  glitchtip-migrate:
    build:
      context: .
      dockerfile: Dockerfile.glitchtip
    container_name: glitchtip-migrate-vps
    command: ./bin/run-migrate.sh
    environment:
      DATABASE_URL: postgres://glitchtip:glitchtip_pass@postgres-glitchtip:5432/glitchtip
      SECRET_KEY: "change_me_to_something_random_please_generate_new_key"
      PORT: 8000
      EMAIL_URL: consolemail://
      GLITCHTIP_DOMAIN: http://localhost:8000
      DEFAULT_FROM_EMAIL: admin@glitchtip.local
      CELERY_WORKER_AUTOSCALE: "1,3"
      REDIS_URL: redis://redis:6379/1
      DEBUG: "false"
      ALLOWED_HOSTS: "localhost,127.0.0.1,glitchtip"
    depends_on:
      - postgres-glitchtip
      - redis
    restart: "no"
    networks:
      - aksi-network-vps
    # Resource limits for migration container
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: "0.25"
        reservations:
          memory: 128M
          cpus: "0.1"

  # Frontend (Next.js) - VPS
  frontend:
    build:
      context: ../frontend
      dockerfile: Dockerfile.dev
    container_name: frontend-vps
    ports:
      - "3000:3000"
    environment:
      NODE_ENV: production
      # Client-side API URL
      NEXT_PUBLIC_API_URL: http://localhost:8080
      # Server-side API URL
      NEXT_SERVER_API_URL: http://backend:8080
      NEXT_TELEMETRY_DISABLED: 1
      # Orval configuration
      ORVAL_API_URL: http://backend:8080/v3/api-docs
      # GlitchTip error monitoring - corrected DSN
      NEXT_PUBLIC_GLITCHTIP_DSN: http://b1abf81086f84a71bc66b1659e647402@glitchtip:8000/1
      GLITCHTIP_ENABLED: "true"
      # VPS optimization - increased memory for 8GB server
      NODE_OPTIONS: "--max-old-space-size=1024 --max-semi-space-size=256"
      # Hot reload disabled for VPS (production-like)
      WATCHPACK_POLLING: "false"
      CHOKIDAR_USEPOLLING: "false"
      # NPM optimization for VPS
      npm_config_audit: "false"
      npm_config_fund: "false"
      npm_config_progress: "false"
      npm_config_cache_max: "86400000"
      npm_config_maxsockets: "10"
      npm_config_audit_level: "none"
    volumes:
      - ../frontend:/app
      - frontend_node_modules:/app/node_modules
      - frontend_next_cache:/app/.next
      - frontend_npm_cache:/home/node/.npm
    depends_on:
      backend:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - aksi-network-vps
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    # Optimized resource limits for 8GB VPS
    deploy:
      resources:
        limits:
          memory: 1.5G
          cpus: "1.0"
        reservations:
          memory: 750M
          cpus: "0.5"

  # Portainer - Docker management
  portainer:
    image: portainer/portainer-ce:latest
    container_name: portainer-vps
    ports:
      - "9000:9000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data_vps:/data
    restart: unless-stopped
    networks:
      - aksi-network-vps
    # Optimized resource limits for 8GB VPS
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: "0.25"
        reservations:
          memory: 128M
          cpus: "0.1"

networks:
  aksi-network-vps:
    driver: bridge

volumes:
  postgres_data_vps:
  postgres_glitchtip_data_vps:
  pgadmin_data_vps:
  frontend_node_modules:
  frontend_next_cache:
  frontend_npm_cache:
  backend_m2_cache:
  backend_uploads:
  glitchtip_uploads_vps:
  portainer_data_vps:
